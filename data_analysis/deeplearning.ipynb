{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "2c29f24f490fc11ce1e48d89a3d8a10c86c424066fbebe55fdecaa30f8bedbaf"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "deeplearning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyMNlZ9rRidk"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqV7lbAhRidq"
      },
      "source": [
        "# DATA load\n",
        "X = pd.read_csv('/loan_train_preprocessed.csv')\n",
        "\n",
        "# backward\n",
        "X = X[['term', 'initial_list_status', 'int_rate', \n",
        "'emp_length', 'annual_inc', 'dti', 'delinq_2yrs', \n",
        "'inq_last_6mths', 'revol_util', 'recoveries', \n",
        "'collection_recovery_fee', 'tot_cur_bal', \n",
        "'home_ownershipRENT', 'purposesmall_business', \n",
        "'purposewedding', 'earliest_cr_line2000']]\n",
        "\n",
        "y = pd.read_csv('/loan_train_label.csv')\n",
        "y = y.drop(['id'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef5ofijbSzUN"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyd6o1w8Rids",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1233abcb-e686-47dd-e868-50694c604629"
      },
      "source": [
        "# Dividing the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.20 )\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.20 )\n",
        "\n",
        "x_train.shape,y_train.shape,x_val.shape,y_val.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10240, 16), (10240, 1), (2560, 16), (2560, 1), (3200, 16), (3200, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LXgrGmRidu"
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwyhZ10JRidw"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(2048, input_shape = (len(x_train.columns),), activation='ELU'))\n",
        "model.add(Dense(1024, activation='ELU'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='ELU'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='ELU'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='ELU'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='ELU'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='ELU'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='ELU'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='ELU'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "             loss = 'binary_crossentropy',\n",
        "             metrics = ['accuracy', f1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wcIXZxCRidx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f655540-2123-4cb1-89ad-bc039d9004f7"
      },
      "source": [
        "# Adjust the weights of the classes since your dataset is HIGHLY IMBALANCED!\n",
        "class_weight = {0: 1.,\n",
        "                1: 1.}\n",
        "\n",
        "model.fit(x_train.values,\n",
        "         y_train.values,\n",
        "         epochs = 300,\n",
        "         batch_size = 2048,\n",
        "         validation_data = (x_val.values, y_val.values), class_weight=class_weight,\n",
        "         callbacks=[EarlyStopping(monitor='val_f1', mode='max', patience=100, restore_best_weights=True)])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 5s 815ms/step - loss: 0.6831 - accuracy: 0.5871 - f1: 0.5855 - val_loss: 0.6106 - val_accuracy: 0.6598 - val_f1: 0.6345\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 4s 749ms/step - loss: 0.6221 - accuracy: 0.6328 - f1: 0.6118 - val_loss: 0.5961 - val_accuracy: 0.6672 - val_f1: 0.6391\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.6030 - accuracy: 0.6560 - f1: 0.6302 - val_loss: 0.5723 - val_accuracy: 0.6699 - val_f1: 0.6514\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 4s 741ms/step - loss: 0.5902 - accuracy: 0.6479 - f1: 0.6396 - val_loss: 0.5714 - val_accuracy: 0.6727 - val_f1: 0.6425\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5794 - accuracy: 0.6595 - f1: 0.6375 - val_loss: 0.5650 - val_accuracy: 0.6707 - val_f1: 0.6753\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 4s 747ms/step - loss: 0.5731 - accuracy: 0.6620 - f1: 0.6382 - val_loss: 0.5616 - val_accuracy: 0.6777 - val_f1: 0.6316\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5737 - accuracy: 0.6626 - f1: 0.6433 - val_loss: 0.5666 - val_accuracy: 0.6621 - val_f1: 0.6711\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5690 - accuracy: 0.6665 - f1: 0.6472 - val_loss: 0.5572 - val_accuracy: 0.6770 - val_f1: 0.6616\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5667 - accuracy: 0.6716 - f1: 0.6519 - val_loss: 0.5578 - val_accuracy: 0.6738 - val_f1: 0.6663\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 4s 731ms/step - loss: 0.5640 - accuracy: 0.6658 - f1: 0.6598 - val_loss: 0.5595 - val_accuracy: 0.6781 - val_f1: 0.6645\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5670 - accuracy: 0.6704 - f1: 0.6576 - val_loss: 0.5577 - val_accuracy: 0.6812 - val_f1: 0.6548\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5662 - accuracy: 0.6633 - f1: 0.6223 - val_loss: 0.5592 - val_accuracy: 0.6773 - val_f1: 0.6710\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5611 - accuracy: 0.6752 - f1: 0.6712 - val_loss: 0.5597 - val_accuracy: 0.6797 - val_f1: 0.6428\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 4s 749ms/step - loss: 0.5618 - accuracy: 0.6726 - f1: 0.6491 - val_loss: 0.5548 - val_accuracy: 0.6812 - val_f1: 0.6557\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 4s 744ms/step - loss: 0.5587 - accuracy: 0.6724 - f1: 0.6456 - val_loss: 0.5564 - val_accuracy: 0.6801 - val_f1: 0.6722\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 4s 730ms/step - loss: 0.5592 - accuracy: 0.6718 - f1: 0.6602 - val_loss: 0.5520 - val_accuracy: 0.6793 - val_f1: 0.6411\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 4s 733ms/step - loss: 0.5586 - accuracy: 0.6710 - f1: 0.6475 - val_loss: 0.5603 - val_accuracy: 0.6793 - val_f1: 0.6781\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5593 - accuracy: 0.6724 - f1: 0.6594 - val_loss: 0.5571 - val_accuracy: 0.6770 - val_f1: 0.6726\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 4s 745ms/step - loss: 0.5598 - accuracy: 0.6756 - f1: 0.6550 - val_loss: 0.5585 - val_accuracy: 0.6758 - val_f1: 0.6683\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5577 - accuracy: 0.6765 - f1: 0.6648 - val_loss: 0.5539 - val_accuracy: 0.6809 - val_f1: 0.6570\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5608 - accuracy: 0.6698 - f1: 0.6541 - val_loss: 0.5520 - val_accuracy: 0.6816 - val_f1: 0.6563\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 4s 743ms/step - loss: 0.5575 - accuracy: 0.6737 - f1: 0.6499 - val_loss: 0.5606 - val_accuracy: 0.6730 - val_f1: 0.6739\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 4s 741ms/step - loss: 0.5601 - accuracy: 0.6739 - f1: 0.6567 - val_loss: 0.5540 - val_accuracy: 0.6754 - val_f1: 0.6547\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5604 - accuracy: 0.6702 - f1: 0.6581 - val_loss: 0.5590 - val_accuracy: 0.6781 - val_f1: 0.6719\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5595 - accuracy: 0.6679 - f1: 0.6465 - val_loss: 0.5554 - val_accuracy: 0.6805 - val_f1: 0.6741\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5571 - accuracy: 0.6746 - f1: 0.6588 - val_loss: 0.5556 - val_accuracy: 0.6816 - val_f1: 0.6383\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 4s 732ms/step - loss: 0.5565 - accuracy: 0.6735 - f1: 0.6602 - val_loss: 0.5585 - val_accuracy: 0.6758 - val_f1: 0.6348\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 4s 741ms/step - loss: 0.5572 - accuracy: 0.6756 - f1: 0.6358 - val_loss: 0.5590 - val_accuracy: 0.6762 - val_f1: 0.6471\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 4s 729ms/step - loss: 0.5553 - accuracy: 0.6817 - f1: 0.6813 - val_loss: 0.5525 - val_accuracy: 0.6781 - val_f1: 0.6465\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 4s 732ms/step - loss: 0.5540 - accuracy: 0.6756 - f1: 0.6397 - val_loss: 0.5556 - val_accuracy: 0.6758 - val_f1: 0.6635\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 4s 747ms/step - loss: 0.5556 - accuracy: 0.6766 - f1: 0.6691 - val_loss: 0.5571 - val_accuracy: 0.6750 - val_f1: 0.6269\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 4s 731ms/step - loss: 0.5534 - accuracy: 0.6817 - f1: 0.6574 - val_loss: 0.5628 - val_accuracy: 0.6625 - val_f1: 0.6726\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5526 - accuracy: 0.6799 - f1: 0.6737 - val_loss: 0.5574 - val_accuracy: 0.6797 - val_f1: 0.6301\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 4s 733ms/step - loss: 0.5520 - accuracy: 0.6825 - f1: 0.6562 - val_loss: 0.5589 - val_accuracy: 0.6750 - val_f1: 0.6642\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 4s 725ms/step - loss: 0.5578 - accuracy: 0.6778 - f1: 0.6662 - val_loss: 0.5608 - val_accuracy: 0.6746 - val_f1: 0.6473\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5552 - accuracy: 0.6812 - f1: 0.6688 - val_loss: 0.5549 - val_accuracy: 0.6742 - val_f1: 0.6617\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5531 - accuracy: 0.6789 - f1: 0.6545 - val_loss: 0.5555 - val_accuracy: 0.6773 - val_f1: 0.6617\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5523 - accuracy: 0.6802 - f1: 0.6648 - val_loss: 0.5528 - val_accuracy: 0.6809 - val_f1: 0.6455\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5509 - accuracy: 0.6841 - f1: 0.6740 - val_loss: 0.5528 - val_accuracy: 0.6777 - val_f1: 0.6525\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5531 - accuracy: 0.6771 - f1: 0.6473 - val_loss: 0.5536 - val_accuracy: 0.6797 - val_f1: 0.6667\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5504 - accuracy: 0.6819 - f1: 0.6653 - val_loss: 0.5544 - val_accuracy: 0.6754 - val_f1: 0.6632\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5607 - accuracy: 0.6774 - f1: 0.6525 - val_loss: 0.5707 - val_accuracy: 0.6676 - val_f1: 0.6538\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5620 - accuracy: 0.6720 - f1: 0.6547 - val_loss: 0.5756 - val_accuracy: 0.6555 - val_f1: 0.6576\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 4s 731ms/step - loss: 0.5671 - accuracy: 0.6696 - f1: 0.6721 - val_loss: 0.5678 - val_accuracy: 0.6773 - val_f1: 0.6065\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5664 - accuracy: 0.6724 - f1: 0.6364 - val_loss: 0.5684 - val_accuracy: 0.6672 - val_f1: 0.6604\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 4s 731ms/step - loss: 0.5626 - accuracy: 0.6733 - f1: 0.6567 - val_loss: 0.5596 - val_accuracy: 0.6711 - val_f1: 0.6383\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 4s 744ms/step - loss: 0.5616 - accuracy: 0.6723 - f1: 0.6584 - val_loss: 0.5590 - val_accuracy: 0.6738 - val_f1: 0.6193\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 4s 733ms/step - loss: 0.5590 - accuracy: 0.6769 - f1: 0.6554 - val_loss: 0.5571 - val_accuracy: 0.6742 - val_f1: 0.6265\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5530 - accuracy: 0.6824 - f1: 0.6569 - val_loss: 0.5602 - val_accuracy: 0.6785 - val_f1: 0.6432\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5510 - accuracy: 0.6857 - f1: 0.6715 - val_loss: 0.5570 - val_accuracy: 0.6777 - val_f1: 0.6413\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5531 - accuracy: 0.6846 - f1: 0.6654 - val_loss: 0.5575 - val_accuracy: 0.6742 - val_f1: 0.6601\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5510 - accuracy: 0.6837 - f1: 0.6700 - val_loss: 0.5528 - val_accuracy: 0.6820 - val_f1: 0.6557\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 4s 733ms/step - loss: 0.5515 - accuracy: 0.6844 - f1: 0.6713 - val_loss: 0.5536 - val_accuracy: 0.6781 - val_f1: 0.6303\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5501 - accuracy: 0.6848 - f1: 0.6754 - val_loss: 0.5541 - val_accuracy: 0.6742 - val_f1: 0.6548\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5503 - accuracy: 0.6858 - f1: 0.6604 - val_loss: 0.5582 - val_accuracy: 0.6723 - val_f1: 0.6709\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 4s 747ms/step - loss: 0.5522 - accuracy: 0.6843 - f1: 0.6710 - val_loss: 0.5590 - val_accuracy: 0.6809 - val_f1: 0.6499\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 4s 739ms/step - loss: 0.5505 - accuracy: 0.6877 - f1: 0.6669 - val_loss: 0.5552 - val_accuracy: 0.6727 - val_f1: 0.6635\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5492 - accuracy: 0.6832 - f1: 0.6737 - val_loss: 0.5597 - val_accuracy: 0.6680 - val_f1: 0.6572\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 4s 749ms/step - loss: 0.5507 - accuracy: 0.6865 - f1: 0.6781 - val_loss: 0.5542 - val_accuracy: 0.6840 - val_f1: 0.6369\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5496 - accuracy: 0.6877 - f1: 0.6627 - val_loss: 0.5551 - val_accuracy: 0.6777 - val_f1: 0.6656\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 4s 746ms/step - loss: 0.5464 - accuracy: 0.6891 - f1: 0.6732 - val_loss: 0.5523 - val_accuracy: 0.6785 - val_f1: 0.6597\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5487 - accuracy: 0.6861 - f1: 0.6698 - val_loss: 0.5577 - val_accuracy: 0.6758 - val_f1: 0.6489\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5452 - accuracy: 0.6919 - f1: 0.6802 - val_loss: 0.5553 - val_accuracy: 0.6777 - val_f1: 0.6591\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 4s 741ms/step - loss: 0.5482 - accuracy: 0.6826 - f1: 0.6566 - val_loss: 0.5554 - val_accuracy: 0.6820 - val_f1: 0.6516\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5494 - accuracy: 0.6826 - f1: 0.6644 - val_loss: 0.5551 - val_accuracy: 0.6789 - val_f1: 0.6500\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5493 - accuracy: 0.6840 - f1: 0.6700 - val_loss: 0.5607 - val_accuracy: 0.6719 - val_f1: 0.6667\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5554 - accuracy: 0.6808 - f1: 0.6710 - val_loss: 0.5604 - val_accuracy: 0.6766 - val_f1: 0.6664\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5505 - accuracy: 0.6858 - f1: 0.6644 - val_loss: 0.5645 - val_accuracy: 0.6695 - val_f1: 0.6697\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 4s 739ms/step - loss: 0.5537 - accuracy: 0.6807 - f1: 0.6730 - val_loss: 0.5597 - val_accuracy: 0.6801 - val_f1: 0.6437\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5494 - accuracy: 0.6840 - f1: 0.6639 - val_loss: 0.5696 - val_accuracy: 0.6613 - val_f1: 0.6739\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 4s 739ms/step - loss: 0.5522 - accuracy: 0.6810 - f1: 0.6575 - val_loss: 0.5587 - val_accuracy: 0.6793 - val_f1: 0.6425\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 4s 759ms/step - loss: 0.5496 - accuracy: 0.6872 - f1: 0.6766 - val_loss: 0.5542 - val_accuracy: 0.6836 - val_f1: 0.6480\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 4s 749ms/step - loss: 0.5447 - accuracy: 0.6883 - f1: 0.6602 - val_loss: 0.5588 - val_accuracy: 0.6734 - val_f1: 0.6753\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 4s 732ms/step - loss: 0.5461 - accuracy: 0.6884 - f1: 0.6834 - val_loss: 0.5568 - val_accuracy: 0.6812 - val_f1: 0.6576\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5474 - accuracy: 0.6889 - f1: 0.6713 - val_loss: 0.5585 - val_accuracy: 0.6750 - val_f1: 0.6535\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5510 - accuracy: 0.6857 - f1: 0.6790 - val_loss: 0.5589 - val_accuracy: 0.6730 - val_f1: 0.6585\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5539 - accuracy: 0.6807 - f1: 0.6627 - val_loss: 0.5607 - val_accuracy: 0.6707 - val_f1: 0.6714\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5520 - accuracy: 0.6844 - f1: 0.6818 - val_loss: 0.5609 - val_accuracy: 0.6836 - val_f1: 0.6498\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5512 - accuracy: 0.6853 - f1: 0.6664 - val_loss: 0.5589 - val_accuracy: 0.6754 - val_f1: 0.6494\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5448 - accuracy: 0.6907 - f1: 0.6698 - val_loss: 0.5603 - val_accuracy: 0.6770 - val_f1: 0.6510\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 4s 739ms/step - loss: 0.5475 - accuracy: 0.6908 - f1: 0.6759 - val_loss: 0.5595 - val_accuracy: 0.6762 - val_f1: 0.6680\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5459 - accuracy: 0.6945 - f1: 0.6899 - val_loss: 0.5627 - val_accuracy: 0.6812 - val_f1: 0.6507\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5467 - accuracy: 0.6934 - f1: 0.6798 - val_loss: 0.5540 - val_accuracy: 0.6820 - val_f1: 0.6488\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5433 - accuracy: 0.6895 - f1: 0.6556 - val_loss: 0.5563 - val_accuracy: 0.6762 - val_f1: 0.6663\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5449 - accuracy: 0.6879 - f1: 0.6868 - val_loss: 0.5554 - val_accuracy: 0.6777 - val_f1: 0.6447\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5457 - accuracy: 0.6862 - f1: 0.6664 - val_loss: 0.5584 - val_accuracy: 0.6727 - val_f1: 0.6507\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 4s 739ms/step - loss: 0.5436 - accuracy: 0.6892 - f1: 0.6736 - val_loss: 0.5590 - val_accuracy: 0.6758 - val_f1: 0.6526\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5435 - accuracy: 0.6939 - f1: 0.6872 - val_loss: 0.5560 - val_accuracy: 0.6734 - val_f1: 0.6470\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5454 - accuracy: 0.6902 - f1: 0.6693 - val_loss: 0.5551 - val_accuracy: 0.6773 - val_f1: 0.6541\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5430 - accuracy: 0.6924 - f1: 0.6693 - val_loss: 0.5595 - val_accuracy: 0.6703 - val_f1: 0.6710\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 4s 734ms/step - loss: 0.5441 - accuracy: 0.6872 - f1: 0.6863 - val_loss: 0.5587 - val_accuracy: 0.6785 - val_f1: 0.6386\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5458 - accuracy: 0.6898 - f1: 0.6722 - val_loss: 0.5576 - val_accuracy: 0.6738 - val_f1: 0.6532\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5440 - accuracy: 0.6909 - f1: 0.6699 - val_loss: 0.5587 - val_accuracy: 0.6734 - val_f1: 0.6568\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 4s 736ms/step - loss: 0.5419 - accuracy: 0.6911 - f1: 0.6863 - val_loss: 0.5580 - val_accuracy: 0.6859 - val_f1: 0.6307\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5452 - accuracy: 0.6879 - f1: 0.6742 - val_loss: 0.5588 - val_accuracy: 0.6727 - val_f1: 0.6608\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 4s 739ms/step - loss: 0.5460 - accuracy: 0.6882 - f1: 0.6653 - val_loss: 0.5596 - val_accuracy: 0.6711 - val_f1: 0.6545\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5404 - accuracy: 0.6915 - f1: 0.6810 - val_loss: 0.5594 - val_accuracy: 0.6797 - val_f1: 0.6572\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 4s 733ms/step - loss: 0.5444 - accuracy: 0.6913 - f1: 0.6824 - val_loss: 0.5602 - val_accuracy: 0.6781 - val_f1: 0.6309\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5460 - accuracy: 0.6877 - f1: 0.6635 - val_loss: 0.5637 - val_accuracy: 0.6715 - val_f1: 0.6617\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5464 - accuracy: 0.6887 - f1: 0.6857 - val_loss: 0.5592 - val_accuracy: 0.6859 - val_f1: 0.6374\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5422 - accuracy: 0.6929 - f1: 0.6784 - val_loss: 0.5595 - val_accuracy: 0.6754 - val_f1: 0.6553\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 4s 747ms/step - loss: 0.5433 - accuracy: 0.6940 - f1: 0.6752 - val_loss: 0.5567 - val_accuracy: 0.6750 - val_f1: 0.6418\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 4s 739ms/step - loss: 0.5428 - accuracy: 0.6959 - f1: 0.6861 - val_loss: 0.5621 - val_accuracy: 0.6684 - val_f1: 0.6508\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5398 - accuracy: 0.6949 - f1: 0.6921 - val_loss: 0.5570 - val_accuracy: 0.6812 - val_f1: 0.6221\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5434 - accuracy: 0.6869 - f1: 0.6685 - val_loss: 0.5573 - val_accuracy: 0.6750 - val_f1: 0.6599\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 4s 753ms/step - loss: 0.5418 - accuracy: 0.6896 - f1: 0.6582 - val_loss: 0.5659 - val_accuracy: 0.6625 - val_f1: 0.6673\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5399 - accuracy: 0.6945 - f1: 0.6915 - val_loss: 0.5605 - val_accuracy: 0.6824 - val_f1: 0.6215\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5418 - accuracy: 0.6942 - f1: 0.6740 - val_loss: 0.5601 - val_accuracy: 0.6738 - val_f1: 0.6726\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 4s 738ms/step - loss: 0.5387 - accuracy: 0.6963 - f1: 0.6786 - val_loss: 0.5572 - val_accuracy: 0.6809 - val_f1: 0.6625\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 4s 737ms/step - loss: 0.5401 - accuracy: 0.6986 - f1: 0.6866 - val_loss: 0.5636 - val_accuracy: 0.6758 - val_f1: 0.6396\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 4s 743ms/step - loss: 0.5393 - accuracy: 0.6993 - f1: 0.6827 - val_loss: 0.5576 - val_accuracy: 0.6801 - val_f1: 0.6541\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 4s 740ms/step - loss: 0.5392 - accuracy: 0.6945 - f1: 0.6812 - val_loss: 0.5638 - val_accuracy: 0.6777 - val_f1: 0.6480\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 4s 741ms/step - loss: 0.5397 - accuracy: 0.6939 - f1: 0.6879 - val_loss: 0.5614 - val_accuracy: 0.6801 - val_f1: 0.6184\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 4s 742ms/step - loss: 0.5452 - accuracy: 0.6873 - f1: 0.6620 - val_loss: 0.5691 - val_accuracy: 0.6703 - val_f1: 0.6611\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 4s 735ms/step - loss: 0.5432 - accuracy: 0.6919 - f1: 0.6831 - val_loss: 0.5680 - val_accuracy: 0.6785 - val_f1: 0.6241\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 4s 741ms/step - loss: 0.5398 - accuracy: 0.6941 - f1: 0.6828 - val_loss: 0.5627 - val_accuracy: 0.6664 - val_f1: 0.6458\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 4s 733ms/step - loss: 0.5425 - accuracy: 0.6901 - f1: 0.6640 - val_loss: 0.5627 - val_accuracy: 0.6746 - val_f1: 0.6678\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23a62c1850>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJKmhB9LRidz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1cd8791-4ab7-4ade-9f43-2d3be1ec8764"
      },
      "source": [
        "y_prediction = model.predict(x_test.values)\n",
        "y_prediction= [1 if i>=0.5 else 0 for i in y_prediction]\n",
        "print(\"The Test Accuracy of the model is: {} %\".format(accuracy_score(y_test.values, y_prediction) * 100.)) \n",
        "print()\n",
        "\n",
        "print(confusion_matrix(y_test.values, y_prediction))\n",
        "print()\n",
        "\n",
        "target_names = ['Fully Paid', 'Charged Off']\n",
        "print(classification_report(y_test, y_prediction, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy of the model is: 68.09375 %\n",
            "\n",
            "[[1036  554]\n",
            " [ 467 1143]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Fully Paid       0.69      0.65      0.67      1590\n",
            " Charged Off       0.67      0.71      0.69      1610\n",
            "\n",
            "    accuracy                           0.68      3200\n",
            "   macro avg       0.68      0.68      0.68      3200\n",
            "weighted avg       0.68      0.68      0.68      3200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}